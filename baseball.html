<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Baseball CNN</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper"
				<!-- Intro -->
				<div id="intro">
					<h1>Baseball CNN</h1>					
					<p>A binary classifier that uses a convolutional neural network to classify dyanmic image data from a baseball video game.</p>
					<ul class="actions">
						<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
					</ul>
				</div>
				
				<!-- Nav -->
				<nav id="nav">
					<ul class="links">
						<li><a href="index.html">About Me</a></li>
						<li><a href="projects.html">My Projects</a></li>
						<li><a href="coursework.html">My Coursework</a></li>							
					</ul>
					<ul class="icons">
						<li><a href="https://www.linkedin.com/in/michael-keller-28006116b/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://github.com/michaelkeller21" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
					</ul>
				</nav>

				<!-- Main -->
					<div id="main">
						<!-- Post -->
							<section class="post">
								<header class="major">									
									<h1>Baseball CNN</h1>
									<p>A binary classifier that uses a convolutional neural network to classify dyanmic image data from a baseball video game.</p>
								</header>								
								<h2>Background</h2>
								<p>While taking my <a href="dl.html">Deep Learning</a> course in Fall 2019, I was given the option to do an implementation 
								of a deep learning concept as a term project. This assignment had a ton of freedom. My partner, Henry Herzfeld 
								<a href="https://github.com/henryherzfeld?tab=overview&org=unitedstates&from=2019-10-01&to=2019-10-15">(Github)</a>
								<a href="https://www.linkedin.com/in/henry-herzfeld-ba799893/">(LinkedIn)</a>, and I knew that we wanted to do a CNN, 
								but we were struggling to come up with a unique idea. Knowing that Deep Learning can be applied to anything if one can clearly 
								define a problem, I came up with a unique idea: what if we use a CNN as a step to improve performance in a sports video game?</p>
								<p>As of this writing, MLB The Show is a baseball simulation video game developed annually by Sony San Diego Studios primarily for 
								the Playstation 4. It is a game franchise that I started playing religiously in 2014 and still enjoy to this day. It provides one
								of the more convincing simulations of MLB action that exists on the market. It does a very nice job of simulating the difficulty of
								arguably one of the hardest things in sports: hitting a baseball.</p>
								<div class="image fit"><img src="images/MTS 20 Cover.jpg" alt="" /></div>
								<p>To demonstrate this, I invite the reader to watch the video below of batting gameplay in MLB The Show 19:</p>
								<div><video width="900" height="900" controls><source type="video/mp4" src="videos/MLB NN Data_.mp4"></video></div>
								<p>From this footage, you can see that the player has very little time to react to the ball coming towards them, right? In fact, this
								video was recorded at 30 frames per second. We found that we can take 15 frames from when the ball is released and roughly obtain the
								frame where the ball reaches home plate. This means that it takes roughly 0.5 seconds from the time the pitch is thrown for it to reach 
								home plate. Not much, right? The challenge comes when trying to figure out the following in those 0.5 seconds:
								<ol>
									<li>The box in the center of the screen that disappears once the pitch is thrown and reappears once the pitch reaches home plate
									represents the strike zone. A ball that is inside the box is a strike, and a ball that is outside the zone is a ball. It is 
									generally good practice for a batter not to swing at any balls. So, a succesful player should be able to determine from the path
									of a pitch whether it is a ball or a strike in the 0.5 seconds mentioned.</li> 
									<li>When should a player swing? This is something that for a while I could only answer with trial and error eith feedback from the 
									game. But, thanks to the footage obtained for this project, I now have a concrete answer. If you look closely, you should be able to 
									see a shadow underneath	the baseball as it travels towards home plate. Pay attention to the point where	green grass becomes
									brown dirt in front of home plate. Generally, if the player swings:</li>
									<ol>
										<li>Right after the shadow of the ball crosses the brown dirt if the pitch is further away horizontally from the batter
										(outside)</li>
										<li>Right as the shadow of the ball crosses the brown dirt if the pitch is going to land in the center of the strike zone</li>
										<li>Right before the shadow of the ball crosses the brown dirt if the pitch is closer horizontally to the batter (inside)</li>
									</ol>
								</ol>
								</p>
								<p>Each of the issues described above can each be its own project. We decided to see if we could use a CNN to address the first 
								problem: classifying balls vs. strikes. </p>
								<h2>Methods</h2>
								<h3>Data Collection</h3>
								<p>With any machine learning problem, the most challenging and time-consuming part is often data collection. This applies to deep 
								learning as well. In order for a convolutional neural network (CNN) to perform classification on image data, we must first collect
								the data. To accomplish this, I used the PS4's built in screen-recording feature. I sat down and recorded several unique, full, 9-inning
								games where I did not swing at any pitches. Then we copied this footage onto a USB drive to examine it from our machines.</p>
								<h3>Labeling</h3>
								<p>Next comes the biggest challenge, labeling. Image classificaion problems often have thousands or tens of thousands of images to use 
								as data. Generally, for a neural network model to measure its performance when it makes a classification, it usually checks its 
								prediction against a "ground-truth answer." So, any pitches used as part of our dataset need to be labeled as "ball" or strike 
								for the purposes of measuring the performance of the network. It is unrealistic to go through the video manually, pick out every
								moment where a pitch begins/ends, and label it manually based on feedback from the game. Henry wrote a <a href="#">labeling script</a> to allow
								us to automate this process for each game I recorded. The script wasn't perfect, but it reduced the time it would take to manually label
								significantly. </p>
								<p>Through this process we were able to obtain 1080 pitches. We stacked 15 consecutive frames of the ball traveling as a single pitch instance. 
								So, we have a total of 16,200 images in our dataset. </p>
								<h3>Downsampling</h3>
								<p>The sample footage shown above was recorded in 720p at 30 frames per second. The videos we used for our project were recorded in 1080p at
								30 frames per second. The computational complexity of a CNN makes it unrealistic to expect that a neural network can train on 16200 1920x1080 RGB
								images in a reasonable amount of time. So, it became necessary to downsample our images. </p>
								<p>So, we changed our images from RGB to grayscale and downsampled them from 1920x1080 to 115x110. Some cropping was also performed to eliminate
								extraneous information from the image. Two samples of frames from a pitch are shown below: </p>
								<div class="image"><img src="images/ball1_0.png" width="115" height="110" alt="" /></div>
								<div class="image"><img src="images/ball1_14.png" width="115" height="110" alt="" /></div>
								<h3>Frame Differencing</h3>
								<p></p>
							</section>
						</div>
				<!-- Footer -->
				<footer id="footer">							
					<section>
						<h3>Email</h3>
						<p>michaelkeller617@gmail.com <br> mkeller2013@fau.edu (valid through December 2020)</a></p>
					</section>
					<section>
						<h3>Social</h3>
						<ul class="icons alt">
							<li><a href="https://www.linkedin.com/in/michael-keller-28006116b/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/michaelkeller21" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</section>						
				</footer>


				<!-- Copyright -->
				<div id="copyright">
					<ul><li>&copy; Michael Keller</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
				</div>
			</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>